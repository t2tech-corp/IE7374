{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d534d006-defc-4d78-801c-e6f834992b7e",
   "metadata": {},
   "source": [
    "### GPT-Neo 125M\n",
    "\n",
    "#### model_name: EleutherAI/gpt-neo-125M\n",
    "#### description: Open-source GPT alternative, trained on diverse text\n",
    "#### pros: More diverse training data, Open source, Good for creative tasks\n",
    "#### cons: Larger than DistilGPT-2, May need more compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18963d5-0d59-4831-897a-a3c8b7c73bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-Neo 125M\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56ec3d7-36f4-4f33-a316-87e11f6538f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-Neo 125M\n",
    "neo_model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "neo_tokenizer = GPT2Tokenizer.from_pretrained(neo_model_name)\n",
    "neo_model = GPTNeoForCausalLM.from_pretrained(neo_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd64a00-70c0-45e2-87bf-e815d1d6981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline\n",
    "neo_text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=neo_model,\n",
    "    tokenizer=neo_tokenizer,\n",
    "    device=-1  # CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e748caa7-5075-402a-9636-92c54654db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPT-Neo 125M with Renaissance poetry prompts\n",
    "def generate_neo_renaissance_poem(prompt, max_new_tokens=35, temperature=0.7):\n",
    "    \"\"\"Generate Renaissance-style poetry using GPT-Neo 125M\"\"\"\n",
    "    result = neo_text_generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=neo_tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.3,\n",
    "        top_p=0.8,\n",
    "        top_k=40,\n",
    "        no_repeat_ngram_size=2\n",
    "    )\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4daf17b-e887-4b56-8535-2bfe3dd9c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPT-Neo with the same prompts we used before\n",
    "test_prompts = [\n",
    "    \"Alas, my heart doth break for thee, sweet love,\",\n",
    "    \"O fairest rose that bloomed in summer's garden,\",\n",
    "    \"When first mine eyes beheld thy gentle face,\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "017787e0-e8ae-48e3-a36b-278adbb6741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1:\n",
      "Prompt: Alas, my heart doth break for thee, sweet love,\n",
      "Generated: Alas, my heart doth break for thee, sweet love, and I will not be\n",
      "more afraid of thee than thou art of mine own.\n",
      "\n",
      "[Illustration: \"I will go away and come back to the palace.\"\n",
      "----------------------------------------\n",
      "Test 2:\n",
      "Prompt: O fairest rose that bloomed in summer's garden,\n",
      "Generated: O fairest rose that bloomed in summer's garden,\n",
      "\n",
      "And the green of the grass, and the sweet fragrance of flowers, were\n",
      "   That came from the water.\n",
      "\f",
      "  3.  The sun was\n",
      "----------------------------------------\n",
      "Test 3:\n",
      "Prompt: When first mine eyes beheld thy gentle face,\n",
      "Generated: When first mine eyes beheld thy gentle face, and I saw the light of thy\n",
      "lips, which was in the midst of my mind, as it were. I took a little\n",
      "while to look at the picture\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(\"Test \" + str(i) + \":\")\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    poem = generate_neo_renaissance_poem(prompt)\n",
    "    print(\"Generated: \" + poem)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb4895-96da-457b-b01f-efc191239edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
