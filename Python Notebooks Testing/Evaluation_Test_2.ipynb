{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca3b462-6af9-4dd0-98ef-067591b18140",
   "metadata": {},
   "source": [
    "## Evaluation & Metrics: Assess model performance using relevant metrics: perplexity, distinct, Self-BLEU\n",
    "\n",
    "### Perplexity:\n",
    "measures how “surprised” a language model is by a given text. Lower perplexity means the model assigns higher probability to the text\n",
    "> \t•\tLower scores indicate the model is better at modeling the style/content of your corpus. \n",
    "\t•\tExtremely low scores can also hint at overly safe or repetitive outputs.\n",
    "\n",
    "### Distinct:\n",
    "quantifies how many unique n-grams appear in the generated texts, relative to the total number of n-grams produced. It’s a simple diversity measure\n",
    "> \t•\tDistinct-1 measures word-level diversity (unigrams).\n",
    "\t•\tDistinct-2 measures phrase-level diversity (bigrams).\n",
    "\t•\tValues closer to 1.0 mean high diversity (few repeats)\n",
    "\t•\tvalues closer to 0 mean the model is repeating the same words/phrases.\n",
    "\n",
    "###  Self-BLEU:\n",
    "evaluates how similar the generated samples are to one another. It’s a reverse of BLEU: treating each generation as a “hypothesis” and all the others as “references.”\n",
    "> \t•\tScores range from 0 to 1.\n",
    "\t•\tHigher Self-BLEU means samples are very similar to each other (low diversity).\n",
    "\t•\tLower Self-BLEU means samples are more distinct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae0624b-6292-46b9-a30d-60aae7f1fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf63f2f1-313a-4582-bed0-d00450c94644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perplexity based on GPT2\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def calc_perplexity(text: str) -> float:\n",
    "    \"\"\"perplexity\"\"\"\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = encodings.input_ids.to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        neg_log_likelihood = outputs.loss * input_ids.shape[1]\n",
    "    ppl = torch.exp(neg_log_likelihood / input_ids.shape[1])\n",
    "    return ppl.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c508c7a-b9cb-4379-be8b-d53eb79524f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distinct\n",
    "\n",
    "def distinct_n(texts, n=1):\n",
    "    \"\"\"Distinct-n = (#unique n-grams) / (#total n-grams)\"\"\"\n",
    "    total_ngrams = 0\n",
    "    unique_ngrams = set()\n",
    "    for txt in texts:\n",
    "        tokens = txt.split()\n",
    "        ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "        count = 0\n",
    "        for ng in ngrams:\n",
    "            unique_ngrams.add(ng)\n",
    "            count += 1\n",
    "        total_ngrams += count\n",
    "    return len(unique_ngrams) / total_ngrams if total_ngrams > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b489e3d-16c9-4a7e-8d81-051e7064ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLEU\n",
    "\n",
    "def self_bleu(texts, n_gram=4):\n",
    "    \"\"\"\n",
    "   Self-BLEU\n",
    "    \"\"\"\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    scores = []\n",
    "    for i, cand in enumerate(texts):\n",
    "        references = [t.split() for j,t in enumerate(texts) if j != i]\n",
    "        scores.append(sentence_bleu(\n",
    "            references=[references],       \n",
    "            hypothesis=cand.split(),\n",
    "            smoothing_function=smoothie,\n",
    "            weights=tuple([1/n_gram]*n_gram)  \n",
    "        ))\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177b2fcf-8a26-4212-9e0f-112798c24f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexities: [46.377098083496094]\n",
      "Avg Perplexity: 46.38\n",
      "Distinct-1: 0.8889\n",
      "Distinct-2: 1.0000\n",
      "Self-BLEU (up to 4-gram): 0.0000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    generated_texts = [\"When first mine eyes beheld thy gentle face, and I saw the light of thylips, which was in the midst of my mind, as it were. I took a little while to look at the picture\" ] #input generated poem \n",
    "\n",
    "    # 4.1 Perplexity\n",
    "    ppls = [calc_perplexity(txt) for txt in generated_texts]\n",
    "    print(\"Perplexities:\", ppls)\n",
    "    print(f\"Avg Perplexity: {sum(ppls)/len(ppls):.2f}\")\n",
    "\n",
    "    # 4.2 Distinct-1 / Distinct-2\n",
    "    print(f\"Distinct-1: {distinct_n(generated_texts, n=1):.4f}\")\n",
    "    print(f\"Distinct-2: {distinct_n(generated_texts, n=2):.4f}\")\n",
    "\n",
    "    # 4.3 Self-BLEU\n",
    "    sb = self_bleu(generated_texts, n_gram=4)\n",
    "    print(f\"Self-BLEU (up to 4-gram): {sb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8afcd81-16f6-4015-9aa0-d195de78a5d7",
   "metadata": {},
   "source": [
    "## Compute style metrics to check how the generated poems style match to training poems\n",
    "\n",
    "### TTR (Type–Token Ratio)\n",
    "> \t•\tHigh TTR (closer to 1): lots of different words — strong variety.\n",
    "\t•\tLow TTR (closer to 0): repeat the same words more often — less variety.\n",
    "\n",
    "### Simpson Diversity Index\n",
    "> \t•\tHigh Simpson (closer to 1): high probability that two randomly picked tokens are different—strong diversity.\n",
    "\t•\tLow Simpson (closer to 0): high chance that two picks are the same token—low diversity.\n",
    "\n",
    "### POS KL Divergence\n",
    "> \t•\tLow KL (near 0): generated poem’s POS mix is very similar to the reference style.\n",
    "\t•\tHigh KL: generated poem’s POS proportions deviate strongly from that style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb9dcc7b-cce2-416a-9e01-56129bf9c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.cli import download as spacy_download\n",
    "from collections import Counter\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2cc0f63-5bbf-4d1a-a653-d8767f169287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "spacy_download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1963f2-4b5f-414a-8efb-da3f4629647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_pos_distribution(texts):\n",
    "    all_pos = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        all_pos.extend([token.pos_ for token in doc if token.is_alpha])\n",
    "    total = len(all_pos)\n",
    "    count = Counter(all_pos)\n",
    "    return {k: v / total for k, v in count.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac9e6a05-2f2c-4209-87a5-6ca05c755780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: When first mine eyes beheld thy gentle face, and I saw the light of thylips, which was in the midst of my mind, as it were. I took a little while to look at the picture\n",
      "  TTR: 0.8889\n",
      "  Simpson Diversity: 0.9921\n",
      "  POS KL Divergence: 0.1913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def compute_style_metrics_en(texts, target_pos_dist):\n",
    "    \"\"\"\n",
    "    Compute style metrics :\n",
    "      - TTR (Type-Token Ratio)\n",
    "      - Simpson Diversity Index\n",
    "      - KL Divergence between POS distributions\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        # Tokenize and keep only alphabetic tokens (lowercased)\n",
    "        doc = nlp(text)\n",
    "        tokens = [token.text.lower() for token in doc if token.is_alpha]\n",
    "        N = len(tokens)\n",
    "\n",
    "        # Compute Type-Token Ratio\n",
    "        unique_tokens = len(set(tokens))\n",
    "        ttr = unique_tokens / N if N else 0.0\n",
    "\n",
    "        # Compute Simpson Diversity Index\n",
    "        freq = Counter(tokens)\n",
    "        simpson = (\n",
    "            1.0 - sum(f * (f - 1) / (N * (N - 1)) for f in freq.values())\n",
    "            if N > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Extract POS tags and compute their distribution\n",
    "        pos_tags = [token.pos_ for token in doc if token.is_alpha]\n",
    "        total_pos = len(pos_tags)\n",
    "        pos_count = Counter(pos_tags)\n",
    "        pos_dist = {\n",
    "            pos: pos_count.get(pos, 0) / total_pos\n",
    "            for pos in target_pos_dist\n",
    "        }\n",
    "\n",
    "        # Compute KL Divergence between the text's POS distribution and the target\n",
    "        kl_div = sum(\n",
    "            p * math.log(p / target_pos_dist[pos])\n",
    "            for pos, p in pos_dist.items()\n",
    "            if p > 0 and target_pos_dist.get(pos, 0) > 0\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            'text': text,\n",
    "            'ttr': ttr,\n",
    "            'simpson_diversity': simpson,\n",
    "            'pos_kl_divergence': kl_div\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #get_reference_pos_distribution(training_poem)\n",
    "    # Example target POS distribution. To get real distribution need to use function \"get_reference_pos_distribution\"\n",
    "    target_pos_dist = {\n",
    "        'NOUN': 0.30,\n",
    "        'VERB': 0.25,\n",
    "        'ADJ': 0.15,\n",
    "        'ADV': 0.10,\n",
    "        'PRON': 0.05,\n",
    "        'ADP': 0.05,\n",
    "        'DET': 0.05,\n",
    "        'CCONJ': 0.05\n",
    "    }\n",
    "\n",
    "    metrics = compute_style_metrics_en(generated_texts, target_pos_dist)\n",
    "    for m in metrics:\n",
    "        print(f\"Text: {m['text']}\")\n",
    "        print(f\"  TTR: {m['ttr']:.4f}\")\n",
    "        print(f\"  Simpson Diversity: {m['simpson_diversity']:.4f}\")\n",
    "        print(f\"  POS KL Divergence: {m['pos_kl_divergence']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286021f4-0f26-4219-83d7-fe038c2d2660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
