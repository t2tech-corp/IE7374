{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3502351-ff2f-40f7-aac9-c86e5ee282dc",
   "metadata": {},
   "source": [
    "#### Model size: DistilGPT-2 has ~82M parameters (vs GPT-2's ~117M)\n",
    "#### Benefits: Faster inference, smaller memory footprint, easier to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a91f67-1363-40c0-8d6c-544ad6aea796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DistilGPT-2 model and tokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfdf43c-0fa7-44cc-b48c-95ffabc790ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DistilGPT-2 (smaller, faster version of GPT-2)\n",
    "distil_model_name = \"distilgpt2\"\n",
    "distil_tokenizer = GPT2Tokenizer.from_pretrained(distil_model_name)\n",
    "distil_model = GPT2LMHeadModel.from_pretrained(distil_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bad017e-4ed7-4586-99ca-a52e575fffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Create text generation pipeline for DistilGPT-2\n",
    "distil_text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=distil_model,\n",
    "    tokenizer=distil_tokenizer,\n",
    "    device=-1  # Use CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e258a097-f521-42a1-9009-3c1a251ae847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Renaissance poetry generation functions for DistilGPT-2\n",
    "def generate_distil_renaissance_poem(prompt, max_new_tokens=40, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Generate Renaissance-style poetry using DistilGPT-2\n",
    "    \"\"\"\n",
    "    result = distil_text_generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=distil_tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.3,\n",
    "        top_p=0.8,\n",
    "        top_k=40,\n",
    "        no_repeat_ngram_size=2\n",
    "    )\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6dcdd3-771e-4a7e-a508-0f05490d323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the same Renaissance prompts with DistilGPT-2\n",
    "renaissance_prompts = [\n",
    "    \"Alas, my heart doth break for thee, sweet love,\",\n",
    "    \"O fairest rose that bloomed in summer's garden,\",\n",
    "    \"When first mine eyes beheld thy gentle face,\",\n",
    "    \"Thy beauty shines like stars in midnight sky,\",\n",
    "    \"Sweet maiden, thou hast stolen my poor heart,\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f5b0240-22f5-4aa7-b71d-3e05ad34e420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: Alas, my heart doth break for thee, sweet love,\n",
      "Generated: Alas, my heart doth break for thee, sweet love, and a blessing to you.\n",
      "I am so glad that I have had such an amazing life! And this is what makes me happy in the first place!!\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Prompt: O fairest rose that bloomed in summer's garden,\n",
      "Generated: O fairest rose that bloomed in summer's garden, but she didn't want to be there.\n",
      "\"I'm not here,\" said a man who was dressed as the Queen of Hearts at an event for \"Fashion Week.\"\n",
      "The men looked\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "Prompt: When first mine eyes beheld thy gentle face,\n",
      "Generated: When first mine eyes beheld thy gentle face, my mouth open and your lips warm with sweetness.\n",
      "Now the other two are being held together in a very strange manner; I can see you both of them smiling! Now they look like their\n",
      "--------------------------------------------------\n",
      "Example 4:\n",
      "Prompt: Thy beauty shines like stars in midnight sky,\n",
      "Generated: Thy beauty shines like stars in midnight sky, and it's so much better than the sun.\n",
      "The beautiful light that has been shining on you is what makes your life more magical!\n",
      "--------------------------------------------------\n",
      "Example 5:\n",
      "Prompt: Sweet maiden, thou hast stolen my poor heart,\n",
      "Generated: Sweet maiden, thou hast stolen my poor heart, thy beloved father. Thou shalt have done what you did to me; and that I will never forget thee!\n",
      "The last time he took a seat at the table of his throne was when it came\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, prompt in enumerate(renaissance_prompts[:5], 1):\n",
    "    print(\"Example \" + str(i) + \":\")\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    poem = generate_distil_renaissance_poem(prompt)\n",
    "    print(\"Generated: \" + poem)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55610b-e72c-4ebc-b971-6861cda8ec58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
