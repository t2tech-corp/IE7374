{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4d2ebe-6ba6-403a-84eb-660520b5e601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in c:\\users\\tterr\\anaconda3\\lib\\site-packages (4.48.3)\n",
      "Requirement already satisfied: torch in c:\\users\\tterr\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: datasets in c:\\users\\tterr\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\tterr\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for GPT-2 and Hugging Face transformers\n",
    "%pip install transformers torch datasets tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f16df1b-7763-4d75-bea1-914e9b096b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for GPT-2 text generation\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6312be2-7993-41f5-a09d-6e170d0aa961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b729d7adf764084adf5d4be7056c6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de90cecfa57840e9855bd249ba17ed13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b49b1e0384d4a5cb17ad84e4521dd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a515292655c43b7a7f101e32010cdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1186188c45ab402ca66d54785a774bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1710717d697d4ed6bd9da20538530c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f47f2763854054870e6114efdd345a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33bfd5f-9038-4d21-bf36-1ab1d94ef8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set up text generation pipeline\n",
    "text_generator = pipeline(\"text-generation\", \n",
    "                         model=model, \n",
    "                         tokenizer=tokenizer,\n",
    "                         device=0 if torch.cuda.is_available() else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c77be29-c2b7-4383-8735-d2bd1c9b95de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaissance love poetry prompts created:\n",
      "1. O fairest maiden, thy beauty doth shine like the morning sun,\n",
      "2. In gardens fair where roses bloom, my heart doth yearn for thee,\n",
      "3. Sweet love, thou art the gentle breeze that stirs my weary soul,\n",
      "4. When Cupid's arrow pierced my heart, I knew that I was thine,\n",
      "5. Beneath the starlit sky so vast, I pledge my love eternal,\n",
      "6. Thy eyes are like the sapphire blue, thy lips like crimson wine,\n",
      "7. In courtly halls where nobles dance, my thoughts are only thee,\n",
      "8. O gentle dove, thy tender voice doth make my spirit soar,\n"
     ]
    }
   ],
   "source": [
    "# Create Renaissance love poetry prompts\n",
    "renaissance_love_prompts = [\n",
    "    \"O fairest maiden, thy beauty doth shine like the morning sun,\",\n",
    "    \"In gardens fair where roses bloom, my heart doth yearn for thee,\",\n",
    "    \"Sweet love, thou art the gentle breeze that stirs my weary soul,\",\n",
    "    \"When Cupid's arrow pierced my heart, I knew that I was thine,\",\n",
    "    \"Beneath the starlit sky so vast, I pledge my love eternal,\",\n",
    "    \"Thy eyes are like the sapphire blue, thy lips like crimson wine,\",\n",
    "    \"In courtly halls where nobles dance, my thoughts are only thee,\",\n",
    "    \"O gentle dove, thy tender voice doth make my spirit soar,\"\n",
    "]\n",
    "\n",
    "print(\"Renaissance love poetry prompts created:\")\n",
    "for i, prompt in enumerate(renaissance_love_prompts, 1):\n",
    "    print(str(i) + \". \" + prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0616895d-3387-4581-966e-e736cc94e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate poems using the Renaissance love prompts\n",
    "def generate_renaissance_poem_fixed(prompt, max_length=100, temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generate Renaissance-style love poetry using GPT-2 - Fixed version\n",
    "    \"\"\"\n",
    "    result = text_generator(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.2,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36d79adf-e3fe-4681-8b6e-b8b0f7bfd680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Renaissance Love Poems:\n",
      "==================================================\n",
      "Prompt 1:\n",
      "O fairest maiden, thy beauty doth shine like the morning sun, and make thee a great star. Now I was no fool of my age; if you'd tell me what this song could be more than that it should contain some interesting or rather amusing verse from one famous man whom every who has heard such music will know to have experienced at his pleasure in an intimate moment with him before many others.\" And as she spoke so they stood silent for quite another ten minutes long until he brought her up again by their side (in all probability also because Mr Pegg knew not where). Afterwards during\n",
      "----------------------------------------\n",
      "Prompt 2:\n",
      "In gardens fair where roses bloom, my heart doth yearn for thee, O Lord! My love is with you a thousand times more than when I was here.\n",
      "I shall not wait to see this world again; be it so long as thou art willing me thy companion:—The joy of the day in which we are all set upon one body will come into reality and bring us together at once or else have none but ourselves on earth forever separated.\"\n",
      "\n",
      "/v^ The following poem follows about two hours later from Vaudeville's book 'A Poem For A Thousand Years\n",
      "----------------------------------------\n",
      "Prompt 3:\n",
      "Sweet love, thou art the gentle breeze that stirs my weary soul, and thy song does it all for me.\n",
      "And in this tender air I breathe out of you with a long sigh to each breath; And every night we will keep on singing together like children at dusk or when sunset comes down from his side.\" —The Divine Comedy.\n",
      "\n",
      ":—I have just learned about God's being born again after death as well as some other stories which depict him having been reborn through life (such could be but one account). It is often said by those who believe he was resurrected because Jesus\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate poems for the first 3 prompts as examples\n",
    "print(\"Generated Renaissance Love Poems:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in range(3):\n",
    "    prompt = renaissance_love_prompts[i]\n",
    "    poem = generate_renaissance_poem(prompt, max_length=120)\n",
    "    print(\"Prompt \" + str(i+1) + \":\")\n",
    "    print(poem)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12957ec9-2b6d-4bab-b0b0-e140020fc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different prompt styles for Renaissance love poetry generation\n",
    "\n",
    "# Style 1: Direct instruction prompt\n",
    "instruction_prompt = \"In the style of a Renaissance Love Poet, create a poem for a long, lost love.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0547f846-f648-4d58-afb6-2393cf61111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with fixed function:\n",
      "1. INSTRUCTION STYLE PROMPT:\n",
      "Prompt: In the style of a Renaissance Love Poet, create a poem for a long, lost love.\n",
      "Type of result: <class 'list'>\n",
      "Generated:\n",
      "In the style of a Renaissance Love Poet, create a poem for a long, lost love. And then you're going to get stuck in this cycle where we want something more than just poetry and our poems will always be better because it's real time so let me explain what I mean about that…\n",
      "A couple days ago at my blog called \"My Story\", he got invited up by someone who gave him $1 million over 10 years (in 2010) from an idea which would make his life very different but also have some big promises: He could put together songs based on any one song or genre/genre; there was no limit as far ASI goes! So here is your plan – find people like Paul McCartney with great ideas such\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the instruction-style prompt\n",
    "print(\"Testing with fixed function:\")\n",
    "print(\"1. INSTRUCTION STYLE PROMPT:\")\n",
    "print(\"Prompt: \" + instruction_prompt)\n",
    "\n",
    "poem1 = generate_renaissance_poem_fixed(instruction_prompt, max_length=150)\n",
    "\n",
    "print(\"Type of result:\", type(poem1))\n",
    "print(\"Generated:\")\n",
    "print(poem1[0]['generated_text'])\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5466fd11-6d07-4831-80fd-e8c7568d02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style 2: Renaissance-style opening lines (more authentic to the period)\n",
    "renaissance_opening = \"Alas, my heart doth weep for love now lost,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8c2c903-9d2e-4267-99b1-891717b96b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with fixed function:\n",
      "2. RENAISSANCE STYLE PROMPT:\n",
      "Prompt: Alas, my heart doth weep for love now lost,\n",
      "Type of result: <class 'list'>\n",
      "Generated:\n",
      "Alas, my heart doth weep for love now lost, that I can no longer remember her.\n",
      "The same day we took leave of our companions to the city and brought with us a small bundle containing several books which were in some measure written by Mary de la Rose: all about God's law; but most important was this new Book entitled \"Anecdotal Histories,\" made up entirely of letters from Holy Maccabees' mother who had never been able or would not have known Jesus Christ as she heard him preach on earth at his trial before Her Majesty King Herod (who still calls Himself John). When She went off into Galilee two years ago he gave these accounts concerning herself only once more when asked whether they contained any\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the Renaissance-style prompt\n",
    "print(\"Testing with fixed function:\")\n",
    "print(\"2. RENAISSANCE STYLE PROMPT:\")\n",
    "print(\"Prompt: \" + renaissance_opening)\n",
    "\n",
    "poem2 = generate_renaissance_poem_fixed(renaissance_opening, max_length=150)\n",
    "\n",
    "print(\"Type of result:\", type(poem2))\n",
    "print(\"Generated:\")\n",
    "print(poem2[0]['generated_text'])\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521644b-a22c-4ae5-81ea-c7a760b9b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style 3: Shakespearean sonnet style opening\n",
    "sonnet_style = \"When I do count the clock that tells the time of love departed,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "263b5797-a374-470b-a1d8-ceb961521401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with fixed function:\n",
      "2. SONNET STYLE PROMPT:\n",
      "Prompt: When I do count the clock that tells the time of love departed,\n",
      "Type of result: <class 'list'>\n",
      "Generated:\n",
      "When I do count the clock that tells the time of love departed, as well as his name and position in history; then it will be clear what we mean by a 'tribute' to our favourite figure.\n",
      "The point is not so much how many people are involved but which part of this story they belong to or who has shared their own picture on social media – any other image can have meaning too (especially for those at odds with themselves). So let's go back two years from now when my wife asked me about her favorite man… she'd seen some great pictures showing him around before he disappeared into obscurity: The most famous thing was Bill Murray wearing an armband like someone had written \"Guns N Roses\" while sitting across\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the Sonnet-style prompt\n",
    "print(\"Testing with fixed function:\")\n",
    "print(\"3. SONNET STYLE PROMPT:\")\n",
    "print(\"Prompt: \" + sonnet_style)\n",
    "\n",
    "poem3 = generate_renaissance_poem_fixed(sonnet_style, max_length=150)\n",
    "\n",
    "print(\"Type of result:\", type(poem3))\n",
    "print(\"Generated:\")\n",
    "print(poem3[0]['generated_text'])\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eecc23a-dd07-44c9-b4df-e26f6cdf456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style 4: Direct Renaissance language\n",
    "direct_renaissance = \"O fairest love, though thou art gone from sight,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd0fc0cf-3860-4beb-9bef-00f3ebed5803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with fixed function:\n",
      "4. DIRECT STYLE PROMPT:\n",
      "Prompt: O fairest love, though thou art gone from sight,\n",
      "Type of result: <class 'list'>\n",
      "Generated:\n",
      "O fairest love, though thou art gone from sight, to live alone; and so shall I be slain by the sword.\n",
      "\n",
      "\n",
      "9 This is true as a proverb: that if you take your life in vain before God's sake--that it may not come into any danger of death or grievous injury—then shouldn't thy soul perish with thee? Then do now what things can ye desire most without giving unto yourself anything but pain! And let all men know this very day when they are at their wits' end because we have forsaken our duty on earth for some other reason than good pleasure rather then just interest-insurance (cf., 3 Ne 10.) The man who seeks revenge must choose his own course accordingly\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the Direct-style prompt\n",
    "print(\"Testing with fixed function:\")\n",
    "print(\"4. DIRECT STYLE PROMPT:\")\n",
    "print(\"Prompt: \" + direct_renaissance)\n",
    "\n",
    "poem4 = generate_renaissance_poem_fixed(direct_renaissance, max_length=150)\n",
    "\n",
    "print(\"Type of result:\", type(poem4))\n",
    "print(\"Generated:\")\n",
    "print(poem4[0]['generated_text'])\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff19fe1f-400b-486a-a233-3bba9c5b6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create better prompts and generation strategies for Renaissance poetry\n",
    "def generate_better_renaissance_poem(prompt, max_new_tokens=40, temperature=0.7, top_p=0.8):\n",
    "    \"\"\"\n",
    "    Optimized function for better Renaissance poetry generation\n",
    "    \"\"\"\n",
    "    result = text_generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,  # Shorter to stay on topic\n",
    "        temperature=temperature,        # Lower for more coherent output\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.3,        # Higher to avoid repetition\n",
    "        top_p=top_p,                   # More focused sampling\n",
    "        top_k=40,                      # Limit vocabulary choices\n",
    "        no_repeat_ngram_size=2         # Prevent repeating phrases\n",
    "    )\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be59ac49-ed60-422a-adb9-303243dc83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better Renaissance-style prompts that work with GPT-2\n",
    "authentic_prompts = [\n",
    "    \"Alas, my heart doth break for thee, sweet love,\",\n",
    "    \"O fairest rose that bloomed in summer's garden,\",\n",
    "    \"When first mine eyes beheld thy gentle face,\",\n",
    "    \"Thy beauty shines like stars in midnight sky,\",\n",
    "    \"Sweet maiden, thou hast stolen my poor heart,\",\n",
    "    \"In dreams I see thee, lost love of my youth,\",\n",
    "    \"O cruel fate that took my love away,\",\n",
    "    \"My soul doth weep for thee, departed one,\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14f12c98-2187-4d94-8b95-65ebbe7eb39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED RENAISSANCE POETRY GENERATION\n",
      "==================================================\n",
      "Example 1:\n",
      "Prompt: Alas, my heart doth break for thee, sweet love,\n",
      "Generated: Alas, my heart doth break for thee, sweet love,\n",
      "'Tis the only hope that can be. But I have not yet had time to mourn; but as soon shall we all rejoice at what has happened! And now comes this letter of mine\n",
      "----------------------------------------\n",
      "Example 2:\n",
      "Prompt: O fairest rose that bloomed in summer's garden,\n",
      "Generated: O fairest rose that bloomed in summer's garden, and the flowers of all ages were as white with a crimson shade.\n",
      "\"A new season is coming!\" cried I to myself; \"and it must be this day! It may not have been\n",
      "----------------------------------------\n",
      "Example 3:\n",
      "Prompt: When first mine eyes beheld thy gentle face,\n",
      "Generated: When first mine eyes beheld thy gentle face, which is as sweet and beautiful in the midst of all things; but now I see thee with my whole heart full-grown. Thou art a woman who loves me so much that she has no desire\n",
      "----------------------------------------\n",
      "Example 4:\n",
      "Prompt: Thy beauty shines like stars in midnight sky,\n",
      "Generated: Thy beauty shines like stars in midnight sky, and the great blue of your heart will be one with me forever.\n",
      "So when you hear that I am looking for a bride from my life's past…you may think it is only after all\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"IMPROVED RENAISSANCE POETRY GENERATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, prompt in enumerate(authentic_prompts[:4], 1):\n",
    "    print(\"Example \" + str(i) + \":\")\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    poem = generate_better_renaissance_poem(prompt)\n",
    "    print(\"Generated: \" + poem)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5919810c-b28e-4097-b629-07139fd2cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try even more focused approach with poetic structure\n",
    "def generate_focused_verse(prompt, max_new_tokens=25, temperature=0.6):\n",
    "    \"\"\"\n",
    "    Very focused generation for maintaining poetic style\n",
    "    \"\"\"\n",
    "    result = text_generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.4,\n",
    "        top_p=0.7,\n",
    "        top_k=30\n",
    "    )\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b4d6eea-57c1-4bd5-a849-e0e47ff18781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try prompts that include more context to guide the style\n",
    "contextual_prompts = [\n",
    "    \"In fair Verona, where my love doth dwell,\",\n",
    "    \"Sonnet to my beloved: O gentle heart,\",\n",
    "    \"Upon a time when knights did court fair maids,\",\n",
    "    \"Elizabethan verse: Sweet love, thou art\",\n",
    "    \"Renaissance ballad: My lady fair and true,\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b51e7eb9-0695-4b63-a2c9-327706fcad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXTUAL RENAISSANCE PROMPTS\n",
      "========================================\n",
      "Attempt 1:\n",
      "Prompt: In fair Verona, where my love doth dwell,\n",
      "Generated: In fair Verona, where my love doth dwell, I have been told that the old man hath made a great deal of money by his own labour.\n",
      "\"But now he\n",
      "------------------------------\n",
      "Attempt 2:\n",
      "Prompt: Sonnet to my beloved: O gentle heart,\n",
      "Generated: Sonnet to my beloved: O gentle heart,\n",
      "(to the mother of mine) and I will not be troubled.\n",
      "\n",
      " (To a woman who is in love with\n",
      "------------------------------\n",
      "Attempt 3:\n",
      "Prompt: Upon a time when knights did court fair maids,\n",
      "Generated: Upon a time when knights did court fair maids, the royal family had become so rich that they could afford to pay for them.\n",
      "\n",
      "\"I'm sorry about my wife\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"CONTEXTUAL RENAISSANCE PROMPTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i, prompt in enumerate(contextual_prompts[:3], 1):\n",
    "    print(\"Attempt \" + str(i) + \":\")\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    verse = generate_focused_verse(prompt)\n",
    "    print(\"Generated: \" + verse)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49653017-1ddd-437f-acda-133cda56b9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
