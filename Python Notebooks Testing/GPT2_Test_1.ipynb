{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4d2ebe-6ba6-403a-84eb-660520b5e601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in c:\\users\\tterr\\anaconda3\\lib\\site-packages (4.48.3)\n",
      "Requirement already satisfied: torch in c:\\users\\tterr\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: datasets in c:\\users\\tterr\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\tterr\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tterr\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for GPT-2 and Hugging Face transformers\n",
    "%pip install transformers torch datasets tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f16df1b-7763-4d75-bea1-914e9b096b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for GPT-2 text generation\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6312be2-7993-41f5-a09d-6e170d0aa961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33bfd5f-9038-4d21-bf36-1ab1d94ef8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set up text generation pipeline\n",
    "text_generator = pipeline(\"text-generation\", \n",
    "                         model=model, \n",
    "                         tokenizer=tokenizer,\n",
    "                         device=0 if torch.cuda.is_available() else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c77be29-c2b7-4383-8735-d2bd1c9b95de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaissance love poetry prompts created:\n",
      "1. O fairest maiden, thy beauty doth shine like the morning sun,\n",
      "2. In gardens fair where roses bloom, my heart doth yearn for thee,\n",
      "3. Sweet love, thou art the gentle breeze that stirs my weary soul,\n",
      "4. When Cupid's arrow pierced my heart, I knew that I was thine,\n",
      "5. Beneath the starlit sky so vast, I pledge my love eternal,\n",
      "6. Thy eyes are like the sapphire blue, thy lips like crimson wine,\n",
      "7. In courtly halls where nobles dance, my thoughts are only thee,\n",
      "8. O gentle dove, thy tender voice doth make my spirit soar,\n"
     ]
    }
   ],
   "source": [
    "# Create Renaissance love poetry prompts\n",
    "renaissance_love_prompts = [\n",
    "    \"O fairest maiden, thy beauty doth shine like the morning sun,\",\n",
    "    \"In gardens fair where roses bloom, my heart doth yearn for thee,\",\n",
    "    \"Sweet love, thou art the gentle breeze that stirs my weary soul,\",\n",
    "    \"When Cupid's arrow pierced my heart, I knew that I was thine,\",\n",
    "    \"Beneath the starlit sky so vast, I pledge my love eternal,\",\n",
    "    \"Thy eyes are like the sapphire blue, thy lips like crimson wine,\",\n",
    "    \"In courtly halls where nobles dance, my thoughts are only thee,\",\n",
    "    \"O gentle dove, thy tender voice doth make my spirit soar,\"\n",
    "]\n",
    "\n",
    "print(\"Renaissance love poetry prompts created:\")\n",
    "for i, prompt in enumerate(renaissance_love_prompts, 1):\n",
    "    print(str(i) + \". \" + prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0616895d-3387-4581-966e-e736cc94e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate poems using the Renaissance love prompts\n",
    "def generate_renaissance_poem(prompt, max_length=50, temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generate Renaissance-style love poetry using GPT-2 - Fixed version\n",
    "    \"\"\"\n",
    "    result = text_generator(\n",
    "        prompt,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.2,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36d79adf-e3fe-4681-8b6e-b8b0f7bfd680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Renaissance Love Poems:\n",
      "==================================================\n",
      "Prompt 1:\n",
      "[{'generated_text': 'O fairest maiden, thy beauty doth shine like the morning sun, and that thou art so beautiful with me as if I were a human being.\"\\n\"I am sorry to be your friend,\" said she. \"Why should you not see'}]\n",
      "--------------------------------------------------\n",
      "Prompt 2:\n",
      "[{'generated_text': 'In gardens fair where roses bloom, my heart doth yearn for thee, O Lord! And I will keep thy commandments from the day thou art born to run away and come forth again; For that is what we have done at home. But'}]\n",
      "--------------------------------------------------\n",
      "Prompt 3:\n",
      "[{'generated_text': 'Sweet love, thou art the gentle breeze that stirs my weary soul, I will take thee back to myself with such a light as this.\\nIt was quite impossible for me not to feel so full of pleasure from those who knew her better than'}]\n",
      "--------------------------------------------------\n",
      "Prompt 4:\n",
      "[{'generated_text': 'When Cupid\\'s arrow pierced my heart, I knew that I was thine, and only a single man could make me his.\\n\\n\"There is no one like you,\" he said solemnly. \"I am not afraid of death or'}]\n",
      "--------------------------------------------------\n",
      "Prompt 5:\n",
      "[{'generated_text': \"Beneath the starlit sky so vast, I pledge my love eternal, and by God's grace it shall be yours. (Ibid., pp. 569-572)\\nWe have to understand that this is not a poem but an\"}]\n",
      "--------------------------------------------------\n",
      "Prompt 6:\n",
      "[{'generated_text': 'Thy eyes are like the sapphire blue, thy lips like crimson wine, and your voice is a gentle whisper. You have seen me many times before; I saw you in her little way when she had been here.\"\\n\"And how'}]\n",
      "--------------------------------------------------\n",
      "Prompt 7:\n",
      "[{'generated_text': 'In courtly halls where nobles dance, my thoughts are only thee, which is to say: The noble king will not have it on his own accord; the queen and her brother shall be a bit more humble than they would if their husband had married'}]\n",
      "--------------------------------------------------\n",
      "Prompt 8:\n",
      "[{'generated_text': \"O gentle dove, thy tender voice doth make my spirit soar,\\n[p. 13] In your hands I pray to God: thou shalt have mercy on me; and if you shall not do it through the Lord's hand alone!\\n\\n\"}]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate poems for the 8 prompts as examples\n",
    "print(\"Generated Renaissance Love Poems:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in range(8):\n",
    "    prompt = renaissance_love_prompts[i]\n",
    "    poem = generate_renaissance_poem(prompt, max_length=50)\n",
    "    print(\"Prompt \" + str(i+1) + \":\")\n",
    "    print(poem)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12957ec9-2b6d-4bab-b0b0-e140020fc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different prompt styles for Renaissance love poetry generation\n",
    "\n",
    "# Style 1: Direct instruction prompt\n",
    "instruction_prompt = \"In the style of a Renaissance Love Poet, create a poem for a long, lost love.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0547f846-f648-4d58-afb6-2393cf61111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with fixed function:\n",
      "1. INSTRUCTION STYLE PROMPT:\n",
      "Prompt: In the style of a Renaissance Love Poet, create a poem for a long, lost love.\n",
      "Type of result: <class 'list'>\n",
      "Generated:\n",
      "In the style of a Renaissance Love Poet, create a poem for a long, lost love. The poetic form is simple and elegant: \"I'm going to die my last night.\"\n",
      "The way you compose these poems may not seem that extraordinary\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the instruction-style prompt\n",
    "print(\"Testing with fixed function:\")\n",
    "print(\"1. INSTRUCTION STYLE PROMPT:\")\n",
    "print(\"Prompt: \" + instruction_prompt)\n",
    "\n",
    "poem1 = generate_renaissance_poem(instruction_prompt, max_length=50)\n",
    "\n",
    "print(\"Type of result:\", type(poem1))\n",
    "print(\"Generated:\")\n",
    "print(poem1[0]['generated_text'])\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5466fd11-6d07-4831-80fd-e8c7568d02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style 2: Renaissance-style opening lines (more authentic to the period)\n",
    "renaissance_opening = \"Alas, my heart doth weep for love now lost,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8c2c903-9d2e-4267-99b1-891717b96b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with fixed function:\n",
      "2. RENAISSANCE STYLE PROMPT:\n",
      "Prompt: Alas, my heart doth weep for love now lost,\n",
      "Type of result: <class 'list'>\n",
      "Generated:\n",
      "Alas, my heart doth weep for love now lost, and the tears of sorrow grieve me at such a time.\n",
      "The very first thing I want to say is that you should not be afraid when it comes to marriage — unless your\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the Renaissance-style prompt\n",
    "print(\"Testing with fixed function:\")\n",
    "print(\"2. RENAISSANCE STYLE PROMPT:\")\n",
    "print(\"Prompt: \" + renaissance_opening)\n",
    "\n",
    "poem2 = generate_renaissance_poem(renaissance_opening, max_length=50)\n",
    "\n",
    "print(\"Type of result:\", type(poem2))\n",
    "print(\"Generated:\")\n",
    "print(poem2[0]['generated_text'])\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d521644b-a22c-4ae5-81ea-c7a760b9b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style 3: Shakespearean sonnet style opening\n",
    "sonnet_style = \"When I do count the clock that tells the time of love departed,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "263b5797-a374-470b-a1d8-ceb961521401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with fixed function:\n",
      "3. SONNET STYLE PROMPT:\n",
      "Prompt: When I do count the clock that tells the time of love departed,\n",
      "Type of result: <class 'list'>\n",
      "Generated:\n",
      "When I do count the clock that tells the time of love departed, it is a good sign. When we die and have no means to find happiness in ourselves again,\" she said on Sunday after leaving her husband's home for an hourlong holiday with\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the Sonnet-style prompt\n",
    "print(\"Testing with fixed function:\")\n",
    "print(\"3. SONNET STYLE PROMPT:\")\n",
    "print(\"Prompt: \" + sonnet_style)\n",
    "\n",
    "poem3 = generate_renaissance_poem(sonnet_style, max_length=50)\n",
    "\n",
    "print(\"Type of result:\", type(poem3))\n",
    "print(\"Generated:\")\n",
    "print(poem3[0]['generated_text'])\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eecc23a-dd07-44c9-b4df-e26f6cdf456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style 4: Direct Renaissance language\n",
    "direct_renaissance = \"O fairest love, though thou art gone from sight,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd0fc0cf-3860-4beb-9bef-00f3ebed5803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with fixed function:\n",
      "4. DIRECT STYLE PROMPT:\n",
      "Prompt: O fairest love, though thou art gone from sight,\n",
      "Type of result: <class 'list'>\n",
      "Generated:\n",
      "O fairest love, though thou art gone from sight, for I saw thee with my own eyes.\n",
      "Thence to the temple of Anu and there sat in a fair table as before; but after an hour or two all went home alone\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the Direct-style prompt\n",
    "print(\"Testing with fixed function:\")\n",
    "print(\"4. DIRECT STYLE PROMPT:\")\n",
    "print(\"Prompt: \" + direct_renaissance)\n",
    "\n",
    "poem4 = generate_renaissance_poem(direct_renaissance, max_length=50)\n",
    "\n",
    "print(\"Type of result:\", type(poem4))\n",
    "print(\"Generated:\")\n",
    "print(poem4[0]['generated_text'])\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff19fe1f-400b-486a-a233-3bba9c5b6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create better prompts and generation strategies for Renaissance poetry\n",
    "def generate_better_renaissance_poem(prompt, max_new_tokens=40, temperature=0.7, top_p=0.8):\n",
    "    \"\"\"\n",
    "    Optimized function for better Renaissance poetry generation\n",
    "    \"\"\"\n",
    "    result = text_generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,  # Shorter to stay on topic\n",
    "        temperature=temperature,        # Lower for more coherent output\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.3,        # Higher to avoid repetition\n",
    "        top_p=top_p,                   # More focused sampling\n",
    "        top_k=40,                      # Limit vocabulary choices\n",
    "        no_repeat_ngram_size=2         # Prevent repeating phrases\n",
    "    )\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be59ac49-ed60-422a-adb9-303243dc83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better Renaissance-style prompts that work with GPT-2\n",
    "authentic_prompts = [\n",
    "    \"Alas, my heart doth break for thee, sweet love,\",\n",
    "    \"O fairest rose that bloomed in summer's garden,\",\n",
    "    \"When first mine eyes beheld thy gentle face,\",\n",
    "    \"Thy beauty shines like stars in midnight sky,\",\n",
    "    \"Sweet maiden, thou hast stolen my poor heart,\",\n",
    "    \"In dreams I see thee, lost love of my youth,\",\n",
    "    \"O cruel fate that took my love away,\",\n",
    "    \"My soul doth weep for thee, departed one,\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14f12c98-2187-4d94-8b95-65ebbe7eb39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED RENAISSANCE POETRY GENERATION\n",
      "==================================================\n",
      "Example 1:\n",
      "Prompt: Alas, my heart doth break for thee, sweet love,\n",
      "Generated: Alas, my heart doth break for thee, sweet love, that I can see you still in the depths of your soul.\n",
      "The only thing left to me is a letter from God and his angels; but it has not yet been delivered! For if we\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Prompt: O fairest rose that bloomed in summer's garden,\n",
      "Generated: O fairest rose that bloomed in summer's garden, and to my delight it was so beautiful as the flowers were blooming.\n",
      "\"Now when I heard this flowery fragrance of spring-time on a white lawn near our house,\" he said with\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "Prompt: When first mine eyes beheld thy gentle face,\n",
      "Generated: When first mine eyes beheld thy gentle face, and when he looked up from his seat I saw him with the great smile of a man who had never seen anything like it.\n",
      "\"I am afraid you will not see me,\" said Mr G\n",
      "--------------------------------------------------\n",
      "Example 4:\n",
      "Prompt: Thy beauty shines like stars in midnight sky,\n",
      "Generated: Thy beauty shines like stars in midnight sky, and the sun is shining at night.\n",
      "\n",
      "\n",
      "You have been trained to be a good warrior by your mother's words of wisdom; you will become an adept fighter for all who need it.\" ―\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"IMPROVED RENAISSANCE POETRY GENERATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, prompt in enumerate(authentic_prompts[:4], 1):\n",
    "    print(\"Example \" + str(i) + \":\")\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    poem = generate_better_renaissance_poem(prompt)\n",
    "    print(\"Generated: \" + poem)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5919810c-b28e-4097-b629-07139fd2cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try even more focused approach with poetic structure\n",
    "def generate_focused_verse(prompt, max_new_tokens=25, temperature=0.6):\n",
    "    \"\"\"\n",
    "    Very focused generation for maintaining poetic style\n",
    "    \"\"\"\n",
    "    result = text_generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.4,\n",
    "        top_p=0.7,\n",
    "        top_k=30\n",
    "    )\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b4d6eea-57c1-4bd5-a849-e0e47ff18781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try prompts that include more context to guide the style\n",
    "contextual_prompts = [\n",
    "    \"In fair Verona, where my love doth dwell,\",\n",
    "    \"Sonnet to my beloved: O gentle heart,\",\n",
    "    \"Upon a time when knights did court fair maids,\",\n",
    "    \"Elizabethan verse: Sweet love, thou art\",\n",
    "    \"Renaissance ballad: My lady fair and true,\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b51e7eb9-0695-4b63-a2c9-327706fcad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXTUAL RENAISSANCE PROMPTS\n",
      "========================================\n",
      "Attempt 1:\n",
      "Prompt: In fair Verona, where my love doth dwell,\n",
      "Generated: In fair Verona, where my love doth dwell, I shall not be able to go.\n",
      "The Lord hath sent me out of the land; and now it is time for\n",
      "------------------------------\n",
      "Attempt 2:\n",
      "Prompt: Sonnet to my beloved: O gentle heart,\n",
      "Generated: Sonnet to my beloved: O gentle heart,\n",
      "'Tis not the time for any man's love; nor is it a day of mourning.\n",
      "\n",
      " (3)\n",
      "------------------------------\n",
      "Attempt 3:\n",
      "Prompt: Upon a time when knights did court fair maids,\n",
      "Generated: Upon a time when knights did court fair maids, they were called \"cousins.\" The commoners of the city's nobility had been known to be quite good at this\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"CONTEXTUAL RENAISSANCE PROMPTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i, prompt in enumerate(contextual_prompts[:3], 1):\n",
    "    print(\"Attempt \" + str(i) + \":\")\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    verse = generate_focused_verse(prompt)\n",
    "    print(\"Generated: \" + verse)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49653017-1ddd-437f-acda-133cda56b9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
